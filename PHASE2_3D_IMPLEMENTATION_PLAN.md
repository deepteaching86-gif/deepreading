# Phase 2: 3D Eye Tracking Implementation Plan

> JEOresearch/EyeTracker ë¶„ì„ ê¸°ë°˜ ê°œì„  ê³„íš
> ìž‘ì„±ì¼: 2025-01-20

## ðŸŽ¯ ëª©í‘œ

í˜„ìž¬ 2D ê¸°ë°˜ ì‹œì„  ì¶”ì ì„ JEOresearchì˜ 3D geometric approachë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì—¬:
- Vertical tracking ì •í™•ë„ 150% í–¥ìƒ
- Head pose ë³€í™”ì— ê°•ê±´í•œ ì‹œìŠ¤í…œ
- ìž¬ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ëŠ” ê±°ë¦¬ ì ì‘

## ðŸ“‹ êµ¬í˜„ ë‹¨ê³„

### Stage 1: Nose-Based Coordinate System (1ì£¼ì°¨)

#### 1.1 Nose Landmarks í™•ìž¥
```typescript
// í˜„ìž¬: 2-3ê°œ nose landmarks
const noseTip = landmarks[1];
const noseBridge = landmarks[168];

// ê°œì„ : 24ê°œ nose landmarks for PCA
const NOSE_INDICES = [4, 45, 275, 220, 440, 1, 5, 51, 281, 44, 274, 
                      241, 461, 125, 354, 218, 438, 195, 167, 393, 
                      165, 391, 3, 248];

const nosePoints = NOSE_INDICES.map(i => landmarks[i]);
```

#### 1.2 PCA ê¸°ë°˜ ì¢Œí‘œê³„ êµ¬ì¶•
```typescript
interface FaceCoordinateSystem {
  center: Point3D;
  axes: Matrix3x3;  // PCA eigenvectors
  scale: number;    // Nose region scale
}

function computeFaceCoordinates(nosePoints: Point3D[]): FaceCoordinateSystem {
  // Center point
  const center = averagePoint(nosePoints);
  
  // Covariance matrix
  const centered = nosePoints.map(p => subtract(p, center));
  const cov = computeCovariance(centered);
  
  // PCA for stable axes
  const { eigenvectors } = eigenDecomposition(cov);
  
  // Reference matrix stabilization (prevent flipping)
  if (previousAxes) {
    eigenvectors = stabilizeAxes(eigenvectors, previousAxes);
  }
  
  return { center, axes: eigenvectors, scale: computeScale(nosePoints) };
}
```

### Stage 2: 3D Eye Sphere Model (1ì£¼ì°¨)

#### 2.1 Eye Sphere Tracking
```typescript
interface EyeSphere3D {
  center: Point3D;       // World coordinates
  localOffset: Point3D;  // Head-relative offset
  radius: number;
}

class EyeSphereTracker {
  private calibrationScale: number;
  private leftEyeOffset: Point3D;
  private rightEyeOffset: Point3D;
  
  calibrate(faceCoords: FaceCoordinateSystem, iris3D: Point3D) {
    // Store eye position as head-relative offset
    this.leftEyeOffset = faceCoords.axes.transpose()
      .multiply(iris3D.subtract(faceCoords.center));
    this.calibrationScale = faceCoords.scale;
  }
  
  track(faceCoords: FaceCoordinateSystem): EyeSphere3D {
    // Scale compensation
    const scaleRatio = faceCoords.scale / this.calibrationScale;
    const scaledOffset = this.leftEyeOffset.multiply(scaleRatio);
    
    // Transform to world coordinates
    const worldCenter = faceCoords.center.add(
      faceCoords.axes.multiply(scaledOffset)
    );
    
    return { 
      center: worldCenter, 
      localOffset: scaledOffset,
      radius: 0.012 * scaleRatio 
    };
  }
}
```

#### 2.2 Binocular Fusion
```typescript
function computeCombinedGaze(
  leftSphere: EyeSphere3D,
  rightSphere: EyeSphere3D,
  leftIris: Point3D,
  rightIris: Point3D
): GazeRay3D {
  // Individual gaze rays
  const leftRay = createRay(leftSphere.center, leftIris);
  const rightRay = createRay(rightSphere.center, rightIris);
  
  // Combined direction (average)
  const combinedDir = normalize(
    leftRay.direction.add(rightRay.direction).divide(2)
  );
  
  // Origin (eye midpoint)
  const origin = leftSphere.center.add(rightSphere.center).divide(2);
  
  return { origin, direction: combinedDir };
}
```

### Stage 3: Ray-Plane Intersection (2ì£¼ì°¨)

#### 3.1 Virtual Monitor Definition
```typescript
interface VirtualMonitor {
  center: Point3D;    // 50cm distance
  normal: Vector3D;   // Perpendicular to screen
  width: number;      // 60cm
  height: number;     // 40cm
}

const VIRTUAL_MONITOR: VirtualMonitor = {
  center: { x: 0, y: 0, z: 500 },  // 500mm from eyes
  normal: { x: 0, y: 0, z: 1 },    // Facing user
  width: 600,   // 600mm
  height: 400   // 400mm
};
```

#### 3.2 Ray-Plane Intersection
```typescript
function computeGazePoint(gazeRay: GazeRay3D, monitor: VirtualMonitor): Point2D {
  // Ray: P = O + t*D
  // Plane: dot(N, P - C) = 0
  
  const O = gazeRay.origin;
  const D = gazeRay.direction;
  const N = monitor.normal;
  const C = monitor.center;
  
  // Solve for t
  const denom = dot(N, D);
  if (Math.abs(denom) < 0.0001) {
    return null; // Ray parallel to plane
  }
  
  const t = dot(N, C.subtract(O)) / denom;
  
  // Intersection point
  const intersection = O.add(D.multiply(t));
  
  // Convert to normalized screen coordinates
  return {
    x: (intersection.x - C.x) / monitor.width + 0.5,
    y: (intersection.y - C.y) / monitor.height + 0.5
  };
}
```

### Stage 4: Enhanced Filtering (2ì£¼ì°¨)

#### 4.1 Deque-Based Smoothing
```typescript
class GazeSmoother {
  private history: Deque<Point3D>;
  private maxLength: number = 5;
  
  addSample(direction: Point3D): Point3D {
    this.history.push(direction);
    if (this.history.length > this.maxLength) {
      this.history.shift();
    }
    
    // Average recent samples
    return this.history.reduce((sum, d) => sum.add(d))
      .divide(this.history.length);
  }
}
```

## ðŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

| Metric | Current (2D) | Phase 2 (3D) | Improvement |
|--------|-------------|--------------|-------------|
| Vertical Tracking | Â±10Â° | Â±20Â° | 100% |
| Head Rotation Tolerance | Â±15Â° | Â±45Â° | 200% |
| Distance Adaptation | Manual | Automatic | âˆž |
| Calibration Frequency | Every session | Once | 90% reduction |
| Jitter (std dev) | 0.5Â° | 0.2Â° | 60% reduction |

## ðŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Week 1 (Critical)
1. âœ… Nose-based coordinate system
2. âœ… 3D eye sphere model
3. âœ… Scale compensation

### Week 2 (Enhancement)
4. âœ… Ray-plane intersection
5. âœ… Deque smoothing
6. âœ… Reference matrix stabilization

### Week 3 (Optimization)
7. â¬œ Performance tuning
8. â¬œ Multi-point calibration
9. â¬œ Production testing

## ðŸ’» í…ŒìŠ¤íŠ¸ ê³„íš

### Unit Tests
- Coordinate system stability
- Scale compensation accuracy
- Ray-plane intersection correctness

### Integration Tests
- Head movement robustness
- Distance change adaptation
- Vertical tracking range

### User Tests
- Calibration ease
- Tracking accuracy
- System responsiveness

## ðŸ“ Migration Strategy

1. **Parallel Implementation**: Keep 2D system while developing 3D
2. **Feature Flag**: `use3DTracking` toggle for A/B testing
3. **Gradual Rollout**: 10% â†’ 50% â†’ 100% users
4. **Fallback Ready**: Instant revert if issues detected

## ðŸŽ¯ Success Metrics

- **Vertical Tracking**: >15Â° range without recalibration
- **User Satisfaction**: >80% prefer 3D over 2D
- **Calibration Time**: <30 seconds one-time setup
- **Accuracy**: <2Â° average error across all head poses

---

**ì°¸ê³  ìžë£Œ**:
- JEOresearch/EyeTracker: https://github.com/JEOresearch/EyeTracker
- MediaPipe Face Mesh: https://google.github.io/mediapipe/solutions/face_mesh
- 3D Computer Vision fundamentals
"""
WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì‹œì„  ì¶”ì  ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
"""
from fastapi import WebSocket
import cv2
import numpy as np
import base64
from typing import Dict
import json
from .tracker import VisionTracker
from .database import save_gaze_data_batch

class VisionWebSocketHandler:
    """Vision ì¶”ì  WebSocket í•¸ë“¤ëŸ¬"""

    def __init__(self):
        self.tracker = VisionTracker()
        self.active_connections: Dict[str, WebSocket] = {}
        self.gaze_buffer: Dict[str, list] = {}  # ë°°ì¹˜ ì €ì¥ìš© ë²„í¼
        self.debug_mode: Dict[str, bool] = {}  # ì„¸ì…˜ë³„ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€

    async def connect(self, websocket: WebSocket, session_id: str):
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        self.gaze_buffer[session_id] = []
        self.debug_mode[session_id] = False  # ê¸°ë³¸ê°’: ë””ë²„ê·¸ ëª¨ë“œ ë¹„í™œì„±í™”
        print(f"Vision session {session_id} connected")

    def disconnect(self, session_id: str):
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ"""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
        if session_id in self.gaze_buffer:
            del self.gaze_buffer[session_id]
        if session_id in self.debug_mode:
            del self.debug_mode[session_id]
        print(f"Vision session {session_id} disconnected")

    async def handle_frame(
        self,
        session_id: str,
        frame_data: Dict
    ):
        """
        í”„ë ˆì„ ìˆ˜ì‹  ë° ì‹œì„  ì¶”ì  ì²˜ë¦¬ (Adaptive Resolution ì§€ì›)

        Args:
            session_id: ì„¸ì…˜ ID
            frame_data: {
                "image": "data:image/jpeg;base64,...",
                "screenWidth": 1920,
                "screenHeight": 1080,
                "frameWidth": 1280,  # ì¹´ë©”ë¼ í”„ë ˆì„ í•´ìƒë„ (adaptive)
                "frameHeight": 720,   # ì¹´ë©”ë¼ í”„ë ˆì„ í•´ìƒë„ (adaptive)
                "enableDebug": false,  # ë””ë²„ê·¸ ì´ë¯¸ì§€ ìƒì„± ì—¬ë¶€ (optional, default: false)
                "timestamp": 1234567890
            }
        """
        websocket = self.active_connections.get(session_id)

        # ë””ë²„ê·¸ ëª¨ë“œ ì—…ë°ì´íŠ¸ (í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ì— ë”°ë¼)
        enable_debug = frame_data.get('enableDebug', False)
        if enable_debug != self.debug_mode.get(session_id, False):
            self.debug_mode[session_id] = enable_debug
            print(f"[{session_id}] ğŸ› Debug mode: {'ON' if enable_debug else 'OFF'}")

        # í”„ë ˆì„ í•´ìƒë„ ì •ë³´ ì¶”ì¶œ (ê¸°ë³¸ê°’: í™”ë©´ í•´ìƒë„ ì‚¬ìš©)
        frame_width = frame_data.get('frameWidth', frame_data['screenWidth'])
        frame_height = frame_data.get('frameHeight', frame_data['screenHeight'])

        # ì²« í”„ë ˆì„ì—ì„œ í•´ìƒë„ ë¡œê¹…
        if session_id not in getattr(self, '_logged_resolutions', set()):
            if not hasattr(self, '_logged_resolutions'):
                self._logged_resolutions = set()
            print(f"[{session_id}] ğŸ“¹ Camera resolution: {frame_width}x{frame_height} (adaptive)")
            print(f"[{session_id}] ğŸ–¥ï¸  Screen resolution: {frame_data['screenWidth']}x{frame_data['screenHeight']}")
            self._logged_resolutions.add(session_id)

        try:
            # Base64 ë””ì½”ë”©
            img_data = base64.b64decode(frame_data['image'].split(',')[1])
            nparr = np.frombuffer(img_data, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if frame is None:
                print(f"[{session_id}] Frame decode failed")
                if websocket:
                    await websocket.send_json({
                        "type": "error",
                        "message": "Frame decode failed"
                    })
                return

            # ì‹œì„  ì¶”ì 
            result = self.tracker.track(frame)

            # ë””ë²„ê·¸ ì´ë¯¸ì§€ ìƒì„± (ì¡°ê±´ë¶€ - ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ)
            debug_image = None
            if self.debug_mode.get(session_id, False):
                debug_frame = self.tracker.draw_debug_overlay(frame, result)
                _, buffer = cv2.imencode('.jpg', debug_frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                debug_image = base64.b64encode(buffer).decode('utf-8')

            if result:
                # í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
                screen_x, screen_y = self.tracker.map_to_screen(
                    np.array(result['gaze_vector']),
                    result['head_pose']['translation'],
                    frame_data['screenWidth'],
                    frame_data['screenHeight']
                )

                # í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
                response = {
                    "type": "gaze_data",
                    "x": screen_x,
                    "y": screen_y,
                    "confidence": result['confidence'],
                    "pupilLeft": result.get('pupil_left'),
                    "pupilRight": result.get('pupil_right'),
                    "headPose": result['head_pose'],
                    "timestamp": frame_data['timestamp']
                }

                # ë””ë²„ê·¸ ì´ë¯¸ì§€ ì¶”ê°€ (ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ)
                if debug_image:
                    response["debugImage"] = f"data:image/jpeg;base64,{debug_image}"

                if websocket:
                    await websocket.send_json(response)

                # ë²„í¼ì— ì¶”ê°€ (ë°°ì¹˜ ì €ì¥)
                self.gaze_buffer[session_id].append(response)

                # 100ê°œë§ˆë‹¤ DB ì €ì¥
                if len(self.gaze_buffer[session_id]) >= 100:
                    await self._flush_buffer(session_id)
            else:
                # Tracking ì‹¤íŒ¨ - ê²½ê³  ì „ì†¡
                print(f"[{session_id}] Tracking failed - no face detected or tracking error")
                if websocket:
                    warning_response = {
                        "type": "warning",
                        "message": "No face detected - please position your face in front of camera"
                    }
                    # ë””ë²„ê·¸ ì´ë¯¸ì§€ ì¶”ê°€ (ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ)
                    if debug_image:
                        warning_response["debugImage"] = f"data:image/jpeg;base64,{debug_image}"
                    await websocket.send_json(warning_response)

        except Exception as e:
            print(f"[{session_id}] Error processing frame: {e}")
            import traceback
            traceback.print_exc()
            if websocket:
                await websocket.send_json({
                    "type": "error",
                    "message": f"Frame processing error: {str(e)}"
                })

    async def _flush_buffer(self, session_id: str):
        """ë²„í¼ì˜ ì‹œì„  ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        if session_id in self.gaze_buffer and self.gaze_buffer[session_id]:
            await save_gaze_data_batch(session_id, self.gaze_buffer[session_id])
            self.gaze_buffer[session_id] = []

    def train_calibration(self, session_id: str, calibration_points: list) -> dict:
        """
        ì„¸ì…˜ë³„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•™ìŠµ

        Args:
            session_id: ì„¸ì…˜ ID
            calibration_points: List of calibration data points

        Returns:
            Calibration metrics dictionary
        """
        print(f"[{session_id}] ğŸ¯ Training calibration with {len(calibration_points)} points")

        # Train the tracker's calibration corrector
        metrics = self.tracker.train_calibration(calibration_points)

        print(f"[{session_id}] âœ… Calibration trained successfully")
        print(f"   Error: {metrics['error_mean']:.1f}px Â± {metrics['error_std']:.1f}px")

        return metrics

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
vision_ws_handler = VisionWebSocketHandler()
